{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/wdwzyyg/ElectronCounting/blob/master/Example_counting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install and import packages"
      ],
      "metadata": {
        "id": "a10vRBPjkY-G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install ElectronCounting --upgrade\n",
        "import CountingNN\n",
        "import torch\n",
        "import os"
      ],
      "metadata": {
        "id": "lvkqGr48kbzs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation funciton"
      ],
      "metadata": {
        "id": "qzHLrhZWDN3x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import pairwise_distances_argmin_min\n",
        "def pos_deviation(coords, truth, threshold):\n",
        "    \"\"\"\n",
        "    Cal the root mean square error between detected electron incident positions and the ground truth positions in units of pixels.\n",
        "    \"\"\"\n",
        "    # elements in pair 1 need to be no less than pair 2\n",
        "    distances = []\n",
        "    if len(coords):\n",
        "      assigment,distances = pairwise_distances_argmin_min(coords, truth)\n",
        "\n",
        "    return distances\n",
        "\n",
        "\n",
        "\n",
        "def end2end_evaluation(groundtruth, predicted, tolerance):\n",
        "  '''\n",
        "  Args:\n",
        "  groundtruth: the ground truth image in electron counts\n",
        "  predicted: model predicted image in electron counts\n",
        "  tolerance: predictions with position error no larger than \"tolerance\" pixels will be selected as truth positive\n",
        "  Returns:\n",
        "  recall\n",
        "  precision\n",
        "  f1\n",
        "  dce: detector conversion efficiency, # of all detected e- / # of ground truth e-\n",
        "  mae_position: mean position error (Euclidean distance) averaged over all the detected electrons within this test image.\n",
        "  '''\n",
        "  truth = []\n",
        "  for value in range(1, 1+int(groundtruth.max())):\n",
        "    truth_ = np.array(np.where(groundtruth==value))\n",
        "    for i in range(value):\n",
        "      truth.append(truth_)\n",
        "  truth = np.hstack(truth).T\n",
        "\n",
        "  predicted_coords = []\n",
        "  for value in range(1, 1 + int(predicted.max())):\n",
        "    coords = np.array(np.where(predicted==value))\n",
        "    for i in range(value):\n",
        "      predicted_coords.append(coords)\n",
        "  predicted_coords = np.hstack(predicted_coords).T\n",
        "\n",
        "  nume = np.sum(groundtruth) # real total number of electron\n",
        "\n",
        "  deviations= pos_deviation(predicted_coords, truth, 6) # square root distance between the ground truth and predicted position for each electron\n",
        "\n",
        "  tp= np.where(deviations<=tolerance)[0].shape[0] # get the true positives, which have the error no larger than \"tolerance\" pixels\n",
        "  precision= tp/deviations.shape[0]\n",
        "  recall = tp/nume\n",
        "\n",
        "  f1 = 2*((precision*recall)/(precision + recall))\n",
        "\n",
        "  dce= len(deviations)/np.sum(groundtruth) # dector conversion efficiency\n",
        "\n",
        "  mae_position = deviations.mean()\n",
        "  print('Recall', recall, 'Precision', precision, 'F1', f1, 'DCE', dce, 'MAE of positions', mae_position)\n",
        "  return recall, precision, f1, dce,mae_position"
      ],
      "metadata": {
        "id": "R5tomVz82IfN"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# counting function using neural network"
      ],
      "metadata": {
        "id": "ZJX7sZh7vqQ9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model\n",
        "# add map_location = 'cpu' when running with on CPU\n",
        "model = torch.load(os.path.dirname(CountingNN.__file__) + '/modelweights/model_200kV_final.pt', map_location=torch.device('cpu'))\n",
        "\n",
        "from CountingNN.locator import Locator\n",
        "\n",
        "def fastrcnn_predict(model, arr, device, process_stride, **kwargs):\n",
        "  \"\"\"\n",
        "  Implements Faster R-CNN on a single image to detect boxes for electron events,\n",
        "  then use finding maximum to assign the entry positions\n",
        "\n",
        "  Args:\n",
        "      model: the loaded fast rcnn model\n",
        "      arr: array of a single image, shape [H,W]\n",
        "      device: torch.device('cpu') or torch.device('cuda')\n",
        "      process_stride: divide the image into pieces when applying the fast rcnn, recommend between 32 and 64.\n",
        "      meanADU: optional float for mean intensity per electron (ADU), if none, will use default 241 for 200kV.\n",
        "      p_list: optional list of five multiplier for model tune, if none, will use default numbers: [6, 6, 1.3, 1.5, 23]\n",
        "  \"\"\"\n",
        "  x = arr[None, ...]\n",
        "  # device =  torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
        "  counting = Locator(model, device, process_stride, 'max', 30, None, 'dynamic_window', meanADU = kwargs.get('meanADU'), p_list=kwargs.get('p_list'))\n",
        "  filtered, event_sizes =  counting.predict_sequence(x)\n",
        "  filtered = filtered[0]\n",
        "\n",
        "  return filtered\n"
      ],
      "metadata": {
        "id": "fdcLcMPovz7j"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run inference and evaluation"
      ],
      "metadata": {
        "id": "FR-14v8AJT1B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example = np.load('/content/Stack016.npz')['X'][0,0]\n",
        "gt = np.load('/content/Stack016.npz')['y'][0,0]\n",
        "# Load your own image array instead\n",
        "example.shape, gt.shape"
      ],
      "metadata": {
        "id": "U_9LbhkCMBZs",
        "outputId": "10983362-f9f7-492a-c86b-e344b3f6e267",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((256, 256), (256, 256))"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_counted = fastrcnn_predict(model, example, device= torch.device('cpu'), process_stride=64)"
      ],
      "metadata": {
        "id": "LGKvJRSim1GR"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "end2end_evaluation(gt, model_counted, tolerance=1)"
      ],
      "metadata": {
        "id": "0INbyYlx_0Xl",
        "outputId": "f0113c90-6b40-4624-db74-0df3985c98bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Recall 0.8203791469194313 Precision 0.7958620689655173 F1 0.8079346557759626 DCE 1.0308056872037914 MAE of positions 0.7154261507604853\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8203791469194313,\n",
              " 0.7958620689655173,\n",
              " 0.8079346557759626,\n",
              " 1.0308056872037914,\n",
              " 0.7154261507604853)"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# counting function using Connected component analysis"
      ],
      "metadata": {
        "id": "Nwdk6ek107S7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.ndimage import maximum_position\n",
        "from scipy.ndimage import label\n",
        "\n",
        "def counting_filter_max(arr, threshold=20, structure = np.ones((3,3))):\n",
        "  \"\"\"\n",
        "  Implements CCA on a single image to detect blobs,\n",
        "  then use finding maximum to assign the entry positions\n",
        "\n",
        "  Args:\n",
        "      arr: array of a single image, shape [H,W]\n",
        "      threshold: dark noise thresholding\n",
        "  \"\"\"\n",
        "  image_binary = arr > threshold\n",
        "  all_labels, num = label(image_binary, structure = np.ones((3,3)))\n",
        "  m=np.ones(shape=all_labels.shape)\n",
        "  obj = maximum_position(arr, all_labels, range(1,num))\n",
        "  obj = np.rint(obj).astype(int)\n",
        "  x = np.zeros(shape=np.shape(arr))\n",
        "  x[obj[:,0],obj[:,1]]=1\n",
        "\n",
        "  return x"
      ],
      "metadata": {
        "id": "ekVyucTW1BTn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Parallel processing"
      ],
      "metadata": {
        "id": "cMUoStQO2V7A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "By using dask, you can create parallel tasks with multiple CPU cores or GPU cores(Dask-Cuda). Just map those counting functions for a lazy signal."
      ],
      "metadata": {
        "id": "TUoi2RSh2bDm"
      }
    }
  ]
}